<!DOCTYPE html>
<html>
<head>
    <title>LabCourseMobileComputerVision</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="style.css">
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-tflite/dist/tf-tflite.min.js"></script>

    <script>
      // WICHTIG: Das hier muss VOR deinem eigenen Script stehen!
      // Wir zwingen TFLite, die Version OHNE SIMD zu nutzen.
      // Der Pfad muss explizit gesetzt werden, sonst sucht er automatisch.
      tflite.setWasmPath('https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-tflite/dist/');
    </script>
</head>

<body>
    <h1>Room Finder</h1>
    <p>Take a picture or upload an image of a supported room.</p>
    
    <video id="video" autoplay playsinline></video>
    <img id="photo" style="display:none; max-width: 100%; margin-top:10px;"/>
    <br><br>
    
    <button id="captureButton" class="btn">Take Image</button>
    <button id="uploadButton" class="btn">Upload Image</button>
    <button id="classifyButton" class="clb">Classify Image</button>
    
    <input type="file" id="fileInput" accept="image/*" style="display:none;"/>
    <canvas id="canvas" style="display:none;"></canvas> 
    
    <div id="resultDiv" class="result" style="margin-top: 20px; font-weight: bold;"></div>

    <script>
        const CLASS_NAMES = [
             'LM_HW_706', 'LM_HW_708', 'LM_HW_709', 'LM_HW_716', 'LM_HW_718', 
             'LM_HW_719', 'LM_North', 'LM_North_East', 'LM_RM_001', 'LM_RM_006', 
             'LM_RM_008', 'LM_RM_012', 'LM_RM_020', 'LM_RM_030', 'LM_RM_126', 
             'LM_South', 'LM_South_East', 'WM_HW_701', 'WM_Main_entrance', 
             'WM_RM_001', 'WM_RM_006', 'WM_RM_009', 'WM_RM_010', 'WM_RM_011', 
             'WM_RM_012', 'WM_RM_019', 'WM_RM_020'
        ];

        let model = null; // Variable global machen

        // Elemente holen
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const photo = document.getElementById('photo');
        const captureButton = document.getElementById('captureButton');
        const resultDiv = document.getElementById('resultDiv');
        const uploadButton = document.getElementById('uploadButton');
        const fileInput = document.getElementById('fileInput');
        const classifyButton = document.getElementById('classifyButton');

        // Kamera starten
        async function startCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { facingMode: "environment" },
                    audio: false
                });
                video.srcObject = stream;
                video.play();
            } catch (err) {
                console.warn("Rückkamera nicht gefunden, versuche Fallback...",err);
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ 
                        video: true,
                        audio: false
                    });
                    video.srcObject = stream;
                    video.play();
                } catch (error2) {
                    console.error("Kamera konnte nicht gestartet werden:", error2);
                    alert("Kamera konnte nicht gestartet werden. Bitte erlaube den Kamerazugriff oder lade ein Bild hoch.");
                }
            }
        }
        window.addEventListener('load', startCamera);

        // Modell Laden (Korrigiert: TFLite direkt laden statt Task API)
        async function loadModel() {
            console.log("Lade Modell...");
            try {
                // Pfad zur .tflite Datei muss stimmen!
                model = await tflite.loadTFLiteModel('tum_rooms_big.tflite', {
                    numThreads: 1,       // Verhindert Threading-Probleme
                    enableXnnpack: false
                });
                console.log("Modell erfolgreich geladen!");
                classifyButton.innerText = "Classify Image (Bereit)";
            } catch (e) {
                console.error("Fehler beim Laden:", e);
                resultDiv.innerText = "Fehler: Modell konnte nicht geladen werden.";
            }
        }
        // Direkt starten
        loadModel();


        // Button Logik
        captureButton.addEventListener("click", () => {
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            const context = canvas.getContext('2d');
            context.drawImage(video, 0, 0, canvas.width, canvas.height);
            photo.src = canvas.toDataURL('image/jpeg');
            photo.style.display = 'inline-block';
            resultDiv.innerText = ""; // Altes Ergebnis löschen
        });

        uploadButton.addEventListener("click", () => fileInput.click());

        fileInput.addEventListener("change", (event) => {
            const file = event.target.files[0];
            if (file) {
                const reader = new FileReader();
                reader.onload = (e) => {
                    photo.src = e.target.result;
                    photo.style.display = 'inline-block';
                    resultDiv.innerText = "";
                };
                reader.readAsDataURL(file);
                event.target.value = '';
            }
        });

        // Die Klassifizierung (Hier war der größte Umbau nötig)
        classifyButton.addEventListener("click", async () => {
            if (!model) return;
            resultDiv.innerText = "Analysiere...";

            let inputTensor = null;
            let outputTensor = null;

            try {
                // 1. Preprocessing (sauber getrennt)
                inputTensor = tf.tidy(() => {
                    let img = tf.browser.fromPixels(photo);
                    img = tf.image.resizeBilinear(img, [224, 224]);
                    img = tf.expandDims(img, 0);
                    // Dein Modell will float32, also durch 255 teilen:
                    return tf.div(tf.cast(img, 'float32'), 255.0);
                });

                // 2. Predict (Muss außerhalb von tf.tidy sein für TFLite!)
                // Der Absturz passiert oft hier, wenn Speicher knapp ist.
                let result = model.predict(inputTensor);

                // Falls Dict zurückkommt, Tensor extrahieren
                if (result instanceof tf.Tensor) {
                    outputTensor = result;
                } else {
                    const keys = Object.keys(result);
                    outputTensor = result[keys[0]];
                    if(keys.length > 1) { 
                        // Speicherleck verhindern bei Dicts
                        Object.keys(result).forEach(k => {
                            if(k !== keys[0]) result[k].dispose();
                        });
                    }
                }

                // 3. WICHTIGSTER FIX: Asynchron warten!
                // Ersetzt .dataSync() -> verhindert WASM Crash
                const values = await outputTensor.data(); 

                // Auswertung
                let maxIndex = 0;
                let maxProb = 0;
                for (let i = 0; i < values.length; i++) {
                    if (values[i] > maxProb) {
                        maxProb = values[i];
                        maxIndex = i;
                    }
                }
                
                const className = CLASS_NAMES[maxIndex] || "Unbekannt";
                const score = (maxProb * 100).toFixed(1);
                resultDiv.innerHTML = `Ergebnis: <br><b>${className}</b> (${score}%)`;

            } catch (error) {
                console.error("Fehler:", error);
                resultDiv.innerText = "Fehler: " + error.message;
            } finally {
                // 4. Aufräumen (extrem wichtig bei WASM)
                if (inputTensor) inputTensor.dispose();
                if (outputTensor) outputTensor.dispose();
            }
        });
    </script>
</body>
</html>
